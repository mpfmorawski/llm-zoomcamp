{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5af0264-ca1f-46a7-ab6f-957c3269d7ad",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02eb1e48-9881-4967-b916-477b01f80b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:13.436874Z",
     "iopub.status.busy": "2024-07-06T15:00:13.436665Z",
     "iopub.status.idle": "2024-07-06T15:00:14.142518Z",
     "shell.execute_reply": "2024-07-06T15:00:14.141951Z",
     "shell.execute_reply.started": "2024-07-06T15:00:13.436853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  6 15:00:13 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984a500f-c66c-4542-9723-c10a318f277d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:14.145181Z",
     "iopub.status.busy": "2024-07-06T15:00:14.144483Z",
     "iopub.status.idle": "2024-07-06T15:00:14.722884Z",
     "shell.execute_reply": "2024-07-06T15:00:14.722267Z",
     "shell.execute_reply.started": "2024-07-06T15:00:14.145142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   39G   62G  39% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   39G   62G  39% /run\n",
      "tmpfs            14G   12K   14G   1% /dev/shm\n",
      "/dev/nvme2n1    2.0G  132M  1.8G   7% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  4.3M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172fd517-5dd6-4364-9f2f-70cb7c8f3833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:22.084740Z",
     "iopub.status.busy": "2024-07-06T15:00:22.084325Z",
     "iopub.status.idle": "2024-07-06T15:00:22.088369Z",
     "shell.execute_reply": "2024-07-06T15:00:22.087614Z",
     "shell.execute_reply.started": "2024-07-06T15:00:22.084710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc1dec-db7a-423e-ab47-a8d1b79c8990",
   "metadata": {},
   "source": [
    "# Running FLAN-T5 XL model on a GPU\n",
    "Source: https://huggingface.co/google/flan-t5-xl#running-the-model-on-a-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98409678-c1df-4084-b54e-affca00b93eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:26.029383Z",
     "iopub.status.busy": "2024-07-06T15:00:26.029033Z",
     "iopub.status.idle": "2024-07-06T15:00:28.723323Z",
     "shell.execute_reply": "2024-07-06T15:00:28.722713Z",
     "shell.execute_reply.started": "2024-07-06T15:00:26.029357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8eedc4-ad17-4bff-9702-c60cd7f6576c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:28.725181Z",
     "iopub.status.busy": "2024-07-06T15:00:28.724714Z",
     "iopub.status.idle": "2024-07-06T15:00:35.851136Z",
     "shell.execute_reply": "2024-07-06T15:00:35.850500Z",
     "shell.execute_reply.started": "2024-07-06T15:00:28.725145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd3654a1cdd49e293c64a3cc3db7466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9918e2-2728-4ae7-96e5-d1481a08deb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:38.989425Z",
     "iopub.status.busy": "2024-07-06T15:00:38.989036Z",
     "iopub.status.idle": "2024-07-06T15:00:38.996475Z",
     "shell.execute_reply": "2024-07-06T15:00:38.995588Z",
     "shell.execute_reply.started": "2024-07-06T15:00:38.989398Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13959,  1566,    12,  2968,    10,   571,   625,    33,    25,    58,\n",
       "             1]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e663b5d-358a-4075-85e2-ff01447896f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:41.216686Z",
     "iopub.status.busy": "2024-07-06T15:00:41.216340Z",
     "iopub.status.idle": "2024-07-06T15:00:42.423125Z",
     "shell.execute_reply": "2024-07-06T15:00:42.422461Z",
     "shell.execute_reply.started": "2024-07-06T15:00:41.216661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 2739, 4445,  436,  292,   58,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(input_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0d99f0-e9cd-4a5e-adf4-0d7370528bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:44.841039Z",
     "iopub.status.busy": "2024-07-06T15:00:44.840654Z",
     "iopub.status.idle": "2024-07-06T15:00:44.846876Z",
     "shell.execute_reply": "2024-07-06T15:00:44.846214Z",
     "shell.execute_reply.started": "2024-07-06T15:00:44.841012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Wie alt sind Sie?</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6682f8-5ca1-48c0-800a-42b75e9520a1",
   "metadata": {},
   "source": [
    "# Building RAG with FLAN-T5 XL\n",
    "Source: https://github.com/DataTalksClub/llm-zoomcamp/blob/main/02-open-source/huggingface-flan-t5.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a7cd8-7b44-4468-86c8-c6e6a9407dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:46.660120Z",
     "iopub.status.busy": "2024-07-06T15:00:46.659741Z",
     "iopub.status.idle": "2024-07-06T15:00:47.930318Z",
     "shell.execute_reply": "2024-07-06T15:00:47.929643Z",
     "shell.execute_reply.started": "2024-07-06T15:00:46.660094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c844e0-686f-41c8-90e1-799e018d8dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:49.406027Z",
     "iopub.status.busy": "2024-07-06T15:00:49.405646Z",
     "iopub.status.idle": "2024-07-06T15:00:50.565385Z",
     "shell.execute_reply": "2024-07-06T15:00:50.564533Z",
     "shell.execute_reply.started": "2024-07-06T15:00:49.405997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f6d945dc220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998e38a9-5b51-4c2b-ba55-1495181c19cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:51.744963Z",
     "iopub.status.busy": "2024-07-06T15:00:51.744535Z",
     "iopub.status.idle": "2024-07-06T15:00:51.749109Z",
     "shell.execute_reply": "2024-07-06T15:00:51.748196Z",
     "shell.execute_reply.started": "2024-07-06T15:00:51.744938Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61606f2e-0f56-4f9d-b2dc-18ee7d515b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:56.853902Z",
     "iopub.status.busy": "2024-07-06T15:00:56.853504Z",
     "iopub.status.idle": "2024-07-06T15:00:56.859138Z",
     "shell.execute_reply": "2024-07-06T15:00:56.858270Z",
     "shell.execute_reply.started": "2024-07-06T15:00:56.853874Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, max_new_tokens=300)\n",
    "    result = tokenizer.decode(outputs[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fecd4f8-dbe5-4eb6-b100-88a901d1dc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:00:58.294238Z",
     "iopub.status.busy": "2024-07-06T15:00:58.293920Z",
     "iopub.status.idle": "2024-07-06T15:00:58.298132Z",
     "shell.execute_reply": "2024-07-06T15:00:58.297471Z",
     "shell.execute_reply.started": "2024-07-06T15:00:58.294215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    print(f\"{prompt=}\")\n",
    "    answer = llm(prompt)\n",
    "    print(f\"\\n{answer=}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2716e75-716c-4ea1-8289-d8ee43367ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:01:00.633352Z",
     "iopub.status.busy": "2024-07-06T15:01:00.632965Z",
     "iopub.status.idle": "2024-07-06T15:01:02.891120Z",
     "shell.execute_reply": "2024-07-06T15:01:02.890401Z",
     "shell.execute_reply.started": "2024-07-06T15:01:00.633324Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=\"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: I just discovered thie course. Can I still join it?\\n\\nCONTEXT:\\nsection: General course-related questions\\nquestion: Course - Can I still join the course after the start date?\\nanswer: Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\\n\\nsection: General course-related questions\\nquestion: Course - Can I follow the course after it finishes?\\nanswer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\\n\\nsection: General course-related questions\\nquestion: Course - When will the course start?\\nanswer: The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\\n\\nsection: General course-related questions\\nquestion: Course - What can I do before the course starts?\\nanswer: You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.\\n\\nsection: General course-related questions\\nquestion: How can we contribute to the course?\\nanswer: Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.\"\n",
      "\n",
      "answer=\"<pad> Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.</s>\"\n"
     ]
    }
   ],
   "source": [
    "rag(\"I just discovered thie course. Can I still join it?\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
