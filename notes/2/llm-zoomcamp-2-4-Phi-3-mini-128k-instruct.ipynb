{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5af0264-ca1f-46a7-ab6f-957c3269d7ad",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02eb1e48-9881-4967-b916-477b01f80b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:00.796544Z",
     "iopub.status.busy": "2024-07-06T15:23:00.795872Z",
     "iopub.status.idle": "2024-07-06T15:23:01.506011Z",
     "shell.execute_reply": "2024-07-06T15:23:01.505274Z",
     "shell.execute_reply.started": "2024-07-06T15:23:00.796514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  6 15:23:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   40C    P0              33W /  70W |   3815MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "984a500f-c66c-4542-9723-c10a318f277d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:05.565799Z",
     "iopub.status.busy": "2024-07-06T15:23:05.565376Z",
     "iopub.status.idle": "2024-07-06T15:23:06.178818Z",
     "shell.execute_reply": "2024-07-06T15:23:06.177817Z",
     "shell.execute_reply.started": "2024-07-06T15:23:05.565769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   35G   66G  35% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   35G   66G  35% /run\n",
      "tmpfs            14G   64K   14G   1% /dev/shm\n",
      "/dev/nvme2n1    2.0G  132M  1.8G   7% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  5.2M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "172fd517-5dd6-4364-9f2f-70cb7c8f3833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:08.040171Z",
     "iopub.status.busy": "2024-07-06T15:23:08.039789Z",
     "iopub.status.idle": "2024-07-06T15:23:08.044203Z",
     "shell.execute_reply": "2024-07-06T15:23:08.043329Z",
     "shell.execute_reply.started": "2024-07-06T15:23:08.040143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8638e247-25c0-447b-af88-5cc106a03e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:09.098659Z",
     "iopub.status.busy": "2024-07-06T15:23:09.098324Z",
     "iopub.status.idle": "2024-07-06T15:23:09.271024Z",
     "shell.execute_reply": "2024-07-06T15:23:09.270308Z",
     "shell.execute_reply.started": "2024-07-06T15:23:09.098634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/cache/hub\n"
     ]
    }
   ],
   "source": [
    "from transformers import TRANSFORMERS_CACHE\n",
    "print(TRANSFORMERS_CACHE)\n",
    "import shutil\n",
    "shutil.rmtree(TRANSFORMERS_CACHE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc1dec-db7a-423e-ab47-a8d1b79c8990",
   "metadata": {},
   "source": [
    "# Running Phi-3-Mini-128K-Instruct model on a GPU\n",
    "Source: https://huggingface.co/microsoft/Phi-3-mini-128k-instruct#sample-inference-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edb5ce49-e7db-496a-b950-63e5ba40bfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:11.527452Z",
     "iopub.status.busy": "2024-07-06T15:23:11.527112Z",
     "iopub.status.idle": "2024-07-06T15:23:11.530755Z",
     "shell.execute_reply": "2024-07-06T15:23:11.530032Z",
     "shell.execute_reply.started": "2024-07-06T15:23:11.527425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8d41481-36dd-438f-b2ca-e30aec4fe929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:53.876531Z",
     "iopub.status.busy": "2024-07-06T15:23:53.876140Z",
     "iopub.status.idle": "2024-07-06T15:23:54.003925Z",
     "shell.execute_reply": "2024-07-06T15:23:54.003194Z",
     "shell.execute_reply.started": "2024-07-06T15:23:53.876507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://stackoverflow.com/a/74012970\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a24f0933-6f4f-4f3e-8c0e-ffebe65cccd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:55.699971Z",
     "iopub.status.busy": "2024-07-06T15:23:55.699605Z",
     "iopub.status.idle": "2024-07-06T15:23:55.704575Z",
     "shell.execute_reply": "2024-07-06T15:23:55.703916Z",
     "shell.execute_reply.started": "2024-07-06T15:23:55.699944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f389bd5d450>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd33c7-e092-41c6-8f67-7a84de8f65cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:23:57.994390Z",
     "iopub.status.busy": "2024-07-06T15:23:57.993883Z",
     "iopub.status.idle": "2024-07-06T15:24:41.902210Z",
     "shell.execute_reply": "2024-07-06T15:24:41.901488Z",
     "shell.execute_reply.started": "2024-07-06T15:23:57.994351Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",  \n",
    "    device_map=\"cuda\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    ") \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e8a22f8-3b40-4eb5-b375-456a3a1a9187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:26:59.976061Z",
     "iopub.status.busy": "2024-07-06T15:26:59.975570Z",
     "iopub.status.idle": "2024-07-06T15:26:59.979824Z",
     "shell.execute_reply": "2024-07-06T15:26:59.978966Z",
     "shell.execute_reply.started": "2024-07-06T15:26:59.976031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline( \n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a77edd56-e462-434b-8c24-2444798bc30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:27:05.960755Z",
     "iopub.status.busy": "2024-07-06T15:27:05.960346Z",
     "iopub.status.idle": "2024-07-06T15:27:13.063327Z",
     "shell.execute_reply": "2024-07-06T15:27:13.062532Z",
     "shell.execute_reply.started": "2024-07-06T15:27:05.960728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve the equation 2x + 3 = 7, follow these steps:\n",
      "\n",
      "1. Subtract 3 from both sides of the equation:\n",
      "   2x + 3 - 3 = 7 - 3\n",
      "   2x = 4\n",
      "\n",
      "2. Divide both sides of the equation by 2:\n",
      "   2x/2 = 4/2\n",
      "   x = 2\n",
      "\n",
      "So, the solution to the equation 2x + 3 = 7 is x = 2.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"}, \n",
    "]\n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"return_full_text\": False, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "output = pipe(messages, **generation_args) \n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6682f8-5ca1-48c0-800a-42b75e9520a1",
   "metadata": {},
   "source": [
    "# Building RAG with Phi-3-Mini-128K-Instruct\n",
    "Source: https://github.com/DataTalksClub/llm-zoomcamp/blob/main/02-open-source/huggingface-phi3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a7cd8-7b44-4468-86c8-c6e6a9407dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:28:44.763709Z",
     "iopub.status.busy": "2024-07-06T15:28:44.763328Z",
     "iopub.status.idle": "2024-07-06T15:28:45.993168Z",
     "shell.execute_reply": "2024-07-06T15:28:45.992347Z",
     "shell.execute_reply.started": "2024-07-06T15:28:44.763681Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60c844e0-686f-41c8-90e1-799e018d8dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:28:48.289196Z",
     "iopub.status.busy": "2024-07-06T15:28:48.288790Z",
     "iopub.status.idle": "2024-07-06T15:28:49.128383Z",
     "shell.execute_reply": "2024-07-06T15:28:49.127788Z",
     "shell.execute_reply.started": "2024-07-06T15:28:48.289167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f3590bfa680>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "998e38a9-5b51-4c2b-ba55-1495181c19cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:28:55.401668Z",
     "iopub.status.busy": "2024-07-06T15:28:55.401165Z",
     "iopub.status.idle": "2024-07-06T15:28:55.405575Z",
     "shell.execute_reply": "2024-07-06T15:28:55.404739Z",
     "shell.execute_reply.started": "2024-07-06T15:28:55.401639Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61606f2e-0f56-4f9d-b2dc-18ee7d515b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:28:58.234554Z",
     "iopub.status.busy": "2024-07-06T15:28:58.234165Z",
     "iopub.status.idle": "2024-07-06T15:28:58.239897Z",
     "shell.execute_reply": "2024-07-06T15:28:58.239240Z",
     "shell.execute_reply.started": "2024-07-06T15:28:58.234524Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\": prompt}, \n",
    "    ]\n",
    "\n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 500, \n",
    "        \"return_full_text\": False, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "\n",
    "    output = pipe(messages, **generation_args) \n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fecd4f8-dbe5-4eb6-b100-88a901d1dc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:29:03.162048Z",
     "iopub.status.busy": "2024-07-06T15:29:03.161631Z",
     "iopub.status.idle": "2024-07-06T15:29:03.168672Z",
     "shell.execute_reply": "2024-07-06T15:29:03.167712Z",
     "shell.execute_reply.started": "2024-07-06T15:29:03.162021Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    print(f\"{prompt=}\")\n",
    "    answer = llm(prompt)\n",
    "    print(f\"\\n{answer=}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2716e75-716c-4ea1-8289-d8ee43367ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T15:29:35.563604Z",
     "iopub.status.busy": "2024-07-06T15:29:35.563225Z",
     "iopub.status.idle": "2024-07-06T15:29:41.610361Z",
     "shell.execute_reply": "2024-07-06T15:29:41.609680Z",
     "shell.execute_reply.started": "2024-07-06T15:29:35.563579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=\"You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: I just discovered thie course. Can I still join it?\\n\\nCONTEXT:\\nsection: General course-related questions\\nquestion: Course - Can I still join the course after the start date?\\nanswer: Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\\n\\nsection: General course-related questions\\nquestion: Course - Can I follow the course after it finishes?\\nanswer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\\n\\nsection: General course-related questions\\nquestion: Course - When will the course start?\\nanswer: The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\\n\\nsection: General course-related questions\\nquestion: Course - What can I do before the course starts?\\nanswer: You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.\\n\\nsection: General course-related questions\\nquestion: How can we contribute to the course?\\nanswer: Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.\"\n",
      "\n",
      "answer=\" I'm sorry, but the provided context does not directly answer the question about joining the course after the start date. However, based on the information given, you can still submit homework even if you don't register before the course starts. Just keep in mind that there will be deadlines for final projects, so it's best to register as soon as possible.\"\n"
     ]
    }
   ],
   "source": [
    "rag(\"I just discovered thie course. Can I still join it?\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
